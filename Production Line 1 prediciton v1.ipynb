{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eason0227/2023-IMBD-final-round/blob/main/Production%20Line%201%20prediciton%20v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5wF-WPosC7iD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ad6sD5-z-JS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.api import ExponentialSmoothing\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import pmdarima as pm\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
        "from sklearn.impute import KNNImputer\n",
        "import optuna\n",
        "from statsmodels.tsa.holtwinters import Holt\n",
        "\n",
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8GhPemOz-JV"
      },
      "outputs": [],
      "source": [
        "anormaly_train1 = pd.read_csv('anomaly_train.csv')\n",
        "\n",
        "for i in range(len(anormaly_train1)):\n",
        "    if anormaly_train1['oven_id'][i] == '1.00E+00':\n",
        "        anormaly_train1['oven_id'][i] = '1E0'\n",
        "    elif anormaly_train1['oven_id'][i] == '2.00E+00':\n",
        "        anormaly_train1['oven_id'][i] = '2E0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YbX3cRbz-JW"
      },
      "outputs": [],
      "source": [
        "# 產線二資料\n",
        "oven,layer,date,anormaly_total_number = [],[],[],[]\n",
        "for d in pd.date_range('2021/12/27','2023/02/06'):\n",
        "  for i in ['2B0','2C0','2D0','2E0','2G0']:\n",
        "    for j in range(1,20):\n",
        "      oven.append(i)\n",
        "      layer.append(j)\n",
        "      date.append(d)\n",
        "      anormaly_total_number.append(0)\n",
        "\n",
        "accumulation = np.zeros(407*5*19)\n",
        "lamp = np.zeros(407*5*19)\n",
        "\n",
        "full_data = {\"oven_id\": oven ,'layer_id':layer,'date':date,\"lamp_id\":lamp,\"anomaly_accumulation_hour\":accumulation,\"anomaly_total_number\":anormaly_total_number }\n",
        "full_data_1 = pd.DataFrame(full_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdkG442-z-JW"
      },
      "outputs": [],
      "source": [
        "# 產線一資料\n",
        "oven,layer,date,anormaly_total_number = [],[],[],[]\n",
        "for d in pd.date_range('2021/12/27','2022/09/01'):\n",
        "  for i in ['1B0','1C0','1D0','1E0','1G0']:\n",
        "    for j in range(1,20):\n",
        "      oven.append(i)\n",
        "      layer.append(j)\n",
        "      date.append(d)\n",
        "      anormaly_total_number.append(0)\n",
        "\n",
        "accumulation = np.zeros(249*5*19)\n",
        "lamp = np.zeros(249*5*19)\n",
        "\n",
        "full_data = {\"oven_id\": oven ,'layer_id':layer,'date':date,\"lamp_id\":lamp,\"anomaly_accumulation_hour\":accumulation,\"anomaly_total_number\":anormaly_total_number }\n",
        "full_data_2 = pd.DataFrame(full_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcUgeSO_z-JX"
      },
      "outputs": [],
      "source": [
        "all_full_data = pd.concat([full_data_1,full_data_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgZWBN0Sz-JX"
      },
      "outputs": [],
      "source": [
        "#建立2021/12/27-2023/02/06有異常的爐和層的資料\n",
        "# anormaly_train_1 = anormaly_train1[['date','oven_id','layer_id','anomaly_total_number']]\n",
        "anormaly_train1['date'] = pd.to_datetime(anormaly_train1['date'],format='%Y-%m-%d')\n",
        "\n",
        "#合併2021/12/27-2023/02/06所有爐和所有層的資料\n",
        "df = pd.concat([anormaly_train1,all_full_data])\n",
        "df.drop_duplicates(subset=['date','oven_id','layer_id'], keep='first', inplace=True)\n",
        "df = df.reset_index().drop(['index'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhUgTV8tz-JX"
      },
      "source": [
        "## 加入新特徵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhnTOxErz-JY",
        "outputId": "b9cf0ba3-440d-490e-c0af-e3553b93c944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "oven_id\n",
              "1B0    8160.736842\n",
              "1C0    7049.114035\n",
              "1D0    7381.078947\n",
              "1E0    6724.149123\n",
              "1G0    2553.850877\n",
              "2B0    6651.411483\n",
              "2C0    7146.488038\n",
              "2D0    7182.669856\n",
              "2E0    5346.928230\n",
              "2G0    1195.425837\n",
              "Name: accumulation_hour, dtype: float64"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accumulation_df = pd.read_csv('accumlation_hour.csv')\n",
        "accumulation_mean = accumulation_df.groupby(['oven_id'])['accumulation_hour'].mean()\n",
        "accumulation_max =  accumulation_df.groupby(['oven_id'])['accumulation_hour'].max()\n",
        "accumulation_min = accumulation_df.groupby(['oven_id'])['accumulation_hour'].min()\n",
        "accumulation_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUWx8Qwvz-JZ"
      },
      "outputs": [],
      "source": [
        "power_df = pd.read_csv('power_sep.csv')\n",
        "def power_setup(accumulation_hour) :\n",
        "    for i in range(len(power_df)):\n",
        "        if accumulation_hour <= power_df['accumulation_hour1'][i] :\n",
        "            break\n",
        "    return power_df['power_setup(other_lamp)'][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnO-imjYz-Ja",
        "outputId": "aabeff21-5384-4b8b-b53d-ca9292192144"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anomaly_total_number</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-12-27</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-28</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-29</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-30</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-28</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-29</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-30</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-01</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            anomaly_total_number\n",
              "date                            \n",
              "2021-12-27                   2.0\n",
              "2021-12-28                   0.0\n",
              "2021-12-29                   0.0\n",
              "2021-12-30                   0.0\n",
              "2021-12-31                   0.0\n",
              "...                          ...\n",
              "2022-08-28                   NaN\n",
              "2022-08-29                   NaN\n",
              "2022-08-30                   NaN\n",
              "2022-08-31                   NaN\n",
              "2022-09-01                   NaN\n",
              "\n",
              "[249 rows x 1 columns]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oven_df = df[df['oven_id']== '1B0' ].sort_values(by='date',ascending=True)\n",
        "oven2_total_anormal = oven_df.groupby(['date'])['anomaly_total_number'].sum()\n",
        "oven_total_anormal = pd.DataFrame(oven2_total_anormal)\n",
        "oven_total_anormal['anomaly_total_number'][-27:] = np.nan\n",
        "oven_total_anormal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2fUCWqmz-Ja"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1bddyNXz-Ja"
      },
      "outputs": [],
      "source": [
        "def creat_feature(oven,days):\n",
        "\n",
        "    oven_df = df[df['oven_id']== oven ].sort_values(by='date',ascending=True)\n",
        "    oven2_total_anormal = oven_df.groupby(['date'])['anomaly_total_number'].sum()\n",
        "    oven_total_anormal = pd.DataFrame(oven2_total_anormal)\n",
        "\n",
        "    for i in range(27): # 產線一預測後27天，加入後27天的row\n",
        "        oven_total_anormal.loc[249+i] = np.nan\n",
        "\n",
        "    oven_total_anormal['oven_id'] = oven\n",
        "\n",
        "    # 過去27天的資料\n",
        "    oven_total_anormal['number_sum'] = np.nan\n",
        "    oven_total_anormal['number_max'] = np.nan\n",
        "    oven_total_anormal['number_min'] =  np.nan\n",
        "    oven_total_anormal['number_mode'] = np.nan\n",
        "    oven_total_anormal['days'] = np.nan\n",
        "\n",
        "    # 每個爐的平均損壞數量\n",
        "    oven_total_anormal['oven_encoder'] = oven_total_anormal['anomaly_total_number'].sum() / np.sum(oven_total_anormal['anomaly_total_number'] >0 )\n",
        "\n",
        "    # 個別爐的水冷板溫度、累積時數、Power setup\n",
        "    if oven == '1B0':\n",
        "        oven_total_anormal['cooler_max'] = 30.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[0] ,accumulation_max[0],accumulation_min[0]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[0])\n",
        "\n",
        "    elif oven == '1C0':\n",
        "        oven_total_anormal['cooler_max'] = 30.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[1],accumulation_max[1],accumulation_min[1]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[1])\n",
        "\n",
        "    elif oven == '1D0':\n",
        "        oven_total_anormal['cooler_max'] = 27.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[2],accumulation_max[2],accumulation_min[2]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[2])\n",
        "\n",
        "    elif oven == '1E0':\n",
        "        oven_total_anormal['cooler_max'] = 27\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[3],accumulation_max[3],accumulation_min[3]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[3])\n",
        "\n",
        "    elif oven == '1G0':\n",
        "        oven_total_anormal['cooler_max'] = 30.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[4],accumulation_max[4],accumulation_min[4]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[4])\n",
        "\n",
        "    elif oven == '2B0':\n",
        "        oven_total_anormal['cooler_max'] = 25.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[5] ,accumulation_max[5],accumulation_min[5]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[5])\n",
        "\n",
        "    elif oven == '2C0':\n",
        "        oven_total_anormal['cooler_max'] = 25.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[6],accumulation_max[6],accumulation_min[6]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[6])\n",
        "\n",
        "    elif oven == '2D0':\n",
        "        oven_total_anormal['cooler_max'] = 26\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[7],accumulation_max[7],accumulation_min[7]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[7])\n",
        "\n",
        "    elif oven == '2E0':\n",
        "        oven_total_anormal['cooler_max'] = 25.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[8],accumulation_max[8],accumulation_min[8]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[8])\n",
        "\n",
        "    elif oven == '2G0':\n",
        "        oven_total_anormal['cooler_max'] = 26.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[9],accumulation_max[9],accumulation_min[9]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[9])\n",
        "\n",
        "    # 過去22天的資料\n",
        "    for i in range(days,len(oven_total_anormal)):\n",
        "        oven_total_anormal['number_sum'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_max'][i] = np.max(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_min'][i] = np.min(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        vals,counts = np.unique( oven_total_anormal[i-days:i][ oven_total_anormal['anomaly_total_number'][i-days:i]>0 ]['anomaly_total_number'],return_counts=True)\n",
        "        try:\n",
        "            index = np.argmax(counts)\n",
        "            oven_total_anormal['number_mode'][i] = vals[index]\n",
        "        except: # 找不到眾數\n",
        "            oven_total_anormal['number_mode'][i] = 0\n",
        "        oven_total_anormal['days'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i] >0 )\n",
        "    return oven_total_anormal\n",
        "\n",
        "def rmse(y,yhat):\n",
        "  return np.sqrt(mean_squared_error(y,yhat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZr9pjpUz-Jb"
      },
      "outputs": [],
      "source": [
        "prediction_days = 27\n",
        "\n",
        "train_df = creat_feature(oven='1B0',days=prediction_days)[:-prediction_days]\n",
        "test_df = creat_feature(oven='1B0',days=prediction_days)[-prediction_days:]\n",
        "\n",
        "for i in ['1C0','1D0','1E0','1G0','2B0','2C0','2D0','2E0','2G0']:\n",
        "    training_df = creat_feature(oven=i,days=prediction_days)[:-prediction_days]\n",
        "    testing_df = creat_feature(oven=i,days=prediction_days)[-prediction_days:]\n",
        "    train_df = pd.concat( [train_df, training_df ])\n",
        "    test_df = pd.concat( [test_df, testing_df ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJC6TM7uz-Jb"
      },
      "outputs": [],
      "source": [
        "train_x = train_df.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "train_y = train_df['anomaly_total_number']\n",
        "\n",
        "lasso_preds,en_preds,lgb_preds,xgb_preds,cat_preds,actual = [],[],[],[],[],[]\n",
        "xgb_params = {'n_estimators': 1300, 'learning_rate': 0.024658403720628174, 'booster': 'gbtree', 'lambda': 8.65039444200474, 'alpha': 7.841025757534408, 'subsample': 0.9651727299534355, 'colsample_bytree': 0.8353388492801248, 'max_depth': 8, 'min_child_weight': 3, 'eta': 0.8339832871331261, 'gamma': 0.6596571553899819, 'grow_policy': 'lossguide'}\n",
        "cat_params = {'iterations': 600, 'learning_rate': 0.08077046387065928, 'depth': 7, 'l2_leaf_reg': 9.566779128474014, 'bagging_temperature': 3.857521071572685, 'random_strength': 4.330651960392663, 'border_count': 47}\n",
        "\n",
        "for i in ['1B0','1C0','1D0','1E0','1G0']:\n",
        "# for i in ['2B0','2C0','2D0','2E0','2G0']:\n",
        "    print(\"============================= oven \"+i+\" =============================\")\n",
        "    test_1 = test_df[test_df['oven_id']==i]\n",
        "    test_1_x = test_1.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "    test_1_y = test_1['anomaly_total_number']\n",
        "\n",
        "    # 执行KNN插补\n",
        "    imputed_data =  KNNImputer(n_neighbors=3).fit_transform(train_x)\n",
        "\n",
        "    lasso_pred = Lasso().fit(imputed_data, train_y).predict(test_1_x)\n",
        "    en_pred = ElasticNet().fit(imputed_data, train_y).predict(test_1_x)\n",
        "    lgb_pred = XGBRegressor(learning_rate=0.01).fit(train_x, train_y).predict(test_1_x)\n",
        "    xgb_pred = LGBMRegressor(learning_rate=0.01,max_depth=5).fit(train_x, train_y).predict(test_1_x)\n",
        "    cat_pred = CatBoostRegressor( random_state=42,silent=True).fit(train_x, train_y).predict(test_1_x) # **cat_params\n",
        "\n",
        "    lasso_preds.append(np.round(np.sum(lasso_pred)))\n",
        "    en_preds.append(np.round(np.sum(en_pred)))\n",
        "    lgb_preds.append(np.round(np.sum(lgb_pred)))\n",
        "    xgb_preds.append(np.round(np.sum(xgb_pred)))\n",
        "    cat_preds.append(np.round(np.sum(cat_pred)))\n",
        "\n",
        "    actual.append(np.sum(test_1_y))\n",
        "\n",
        "    print('Actual number :',actual[-1] ,'| lasso :',lasso_preds[-1],'| ElasticNet :', en_preds[-1],'| LGBM :',lgb_preds[-1],'| XGB :',xgb_preds[-1],'| Catboost : ',cat_preds[-1])\n",
        "    plt.figure(figsize = (10,4), dpi = 100, linewidth = 2)\n",
        "    plt.plot( test_1.index, test_1_y , 'p-', label= 'anomaly_total_number',marker='.')\n",
        "    plt.plot( test_1.index , lasso_pred , 'p-', label= 'LASSO ',marker='.')\n",
        "    plt.plot( test_1.index , en_pred , 'p-', label= 'ElasticNet ',marker='.')\n",
        "    plt.plot( test_1.index , lgb_pred , 'p-', label= 'LGBM ',marker='.')\n",
        "    plt.plot( test_1.index , xgb_pred , 'p-', label= 'XGB ',marker='.')\n",
        "    plt.plot( test_1.index , cat_pred , 'p-', label= 'Catboost ',marker='.')\n",
        "    plt.title(i , x = 0.5, y = 1.03)\n",
        "    plt.yticks(fontsize = 10)\n",
        "    plt.xlabel(\"date\", fontsize = 8, labelpad = 5)\n",
        "    plt.ylabel(\"anomaly_total_number\", fontsize = 10, labelpad = 5)\n",
        "    plt.legend(loc = \"best\", fontsize = 8)\n",
        "    plt.plot()\n",
        "\n",
        "print(\"=\"*110)\n",
        "print('lasso RMSE=',rmse(lasso_preds,actual))\n",
        "print('ElasticNet RMSE=',rmse(en_preds,actual))\n",
        "print('LGBM RMSE=',rmse(lgb_preds,actual))\n",
        "print('XGB RMSE=',rmse(xgb_preds,actual))\n",
        "print('Catboost RMSE=',rmse(cat_preds,actual))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZXrMSDZz-Jc"
      },
      "source": [
        "## 逐步加入預測值 - 最終測試預測結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGQEs_-4z-Jc"
      },
      "outputs": [],
      "source": [
        "def creat_feature(oven,days,new_prediction):\n",
        "    oven_df = df[df['oven_id']== oven ].sort_values(by='date',ascending=True)\n",
        "    oven2_total_anormal = oven_df.groupby(['date'])['anomaly_total_number'].sum()\n",
        "    oven_total_anormal = pd.DataFrame(oven2_total_anormal)\n",
        "\n",
        "    for i in range(27): # 產線一預測後27天，加入後27天的row\n",
        "        oven_total_anormal.loc[249+i] = np.nan\n",
        "\n",
        "    if len(new_prediction) != 0:\n",
        "        for i in range(len(new_prediction)):\n",
        "            oven_total_anormal.loc[249+i] = new_prediction[i]\n",
        "\n",
        "    oven_total_anormal['oven_id'] = oven\n",
        "\n",
        "    # 過去27天的資料\n",
        "    oven_total_anormal['number_sum'] = np.nan\n",
        "    oven_total_anormal['number_max'] = np.nan\n",
        "    oven_total_anormal['number_min'] =  np.nan\n",
        "    oven_total_anormal['number_mode'] = np.nan\n",
        "    oven_total_anormal['days'] = np.nan\n",
        "\n",
        "    # 每個爐的平均損壞數量\n",
        "    oven_total_anormal['oven_encoder'] = oven_total_anormal['anomaly_total_number'].sum() / np.sum(oven_total_anormal['anomaly_total_number'] >0 )\n",
        "\n",
        "    # 個別爐的水冷板溫度、累積時數、Power setup\n",
        "    if oven == '1B0':\n",
        "        oven_total_anormal['cooler_max'] = 30.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[0] ,accumulation_max[0],accumulation_min[0]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[0])\n",
        "\n",
        "    elif oven == '1C0':\n",
        "        oven_total_anormal['cooler_max'] = 30.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[1],accumulation_max[1],accumulation_min[1]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[1])\n",
        "\n",
        "    elif oven == '1D0':\n",
        "        oven_total_anormal['cooler_max'] = 27.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[2],accumulation_max[2],accumulation_min[2]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[2])\n",
        "\n",
        "    elif oven == '1E0':\n",
        "        oven_total_anormal['cooler_max'] = 27\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[3],accumulation_max[3],accumulation_min[3]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[3])\n",
        "\n",
        "    elif oven == '1G0':\n",
        "        oven_total_anormal['cooler_max'] = 30.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[4],accumulation_max[4],accumulation_min[4]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[4])\n",
        "\n",
        "    elif oven == '2B0':\n",
        "        oven_total_anormal['cooler_max'] = 25.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[5] ,accumulation_max[5],accumulation_min[5]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[5])\n",
        "\n",
        "    elif oven == '2C0':\n",
        "        oven_total_anormal['cooler_max'] = 25.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[6],accumulation_max[6],accumulation_min[6]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[6])\n",
        "\n",
        "    elif oven == '2D0':\n",
        "        oven_total_anormal['cooler_max'] = 26\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[7],accumulation_max[7],accumulation_min[7]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[7])\n",
        "\n",
        "    elif oven == '2E0':\n",
        "        oven_total_anormal['cooler_max'] = 25.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[8],accumulation_max[8],accumulation_min[8]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[8])\n",
        "\n",
        "    elif oven == '2G0':\n",
        "        oven_total_anormal['cooler_max'] = 26.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[9],accumulation_max[9],accumulation_min[9]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[9])\n",
        "\n",
        "    # 過去22天的資料\n",
        "    for i in range(days,len(oven_total_anormal)):\n",
        "        oven_total_anormal['number_sum'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_max'][i] = np.max(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_min'][i] = np.min(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        vals,counts = np.unique( oven_total_anormal[i-days:i][ oven_total_anormal['anomaly_total_number'][i-days:i]>0 ]['anomaly_total_number'],return_counts=True)\n",
        "        try:\n",
        "            index = np.argmax(counts)\n",
        "            oven_total_anormal['number_mode'][i] = vals[index]\n",
        "        except: # 找不到眾數\n",
        "            oven_total_anormal['number_mode'][i] = 0\n",
        "        oven_total_anormal['days'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i] >0 )\n",
        "    return oven_total_anormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh7xNsEfz-Jc",
        "outputId": "da2ad752-5ecd-4590-eac7-728820b5422d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 [2.14568213]\n",
            "26 [2.10382328]\n",
            "25 [2.20092832]\n",
            "24 [2.06186752]\n",
            "23 [2.16000944]\n",
            "22 [1.86308921]\n",
            "21 [1.95574551]\n",
            "20 [2.04458044]\n",
            "19 [2.17797852]\n",
            "18 [2.13055242]\n",
            "17 [2.1097335]\n",
            "16 [2.234322]\n",
            "15 [2.24828771]\n",
            "14 [2.03359]\n",
            "13 [2.10106217]\n",
            "12 [2.10117033]\n",
            "11 [2.09354391]\n",
            "10 [2.10293022]\n",
            "9 [2.09945216]\n",
            "8 [2.09578349]\n",
            "7 [2.08443605]\n",
            "6 [2.08172629]\n",
            "5 [2.07826225]\n",
            "4 [2.07446815]\n",
            "3 [2.07461535]\n",
            "2 [2.07491307]\n",
            "1 [2.07520772]\n"
          ]
        }
      ],
      "source": [
        "lasso_preds = []\n",
        "for i in range(27,0,-1):\n",
        "    prediction_days = i\n",
        "    all_df = creat_feature(oven='1B0',days = prediction_days, new_prediction = lasso_preds )\n",
        "    train_df = creat_feature(oven='1B0',days = prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "\n",
        "    if prediction_days == 1 :\n",
        "        test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[-2:-1]\n",
        "    else:\n",
        "        test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[-prediction_days: - prediction_days+1 ]\n",
        "\n",
        "    for i in ['1C0','1D0','1E0','1G0','2B0','2C0','2D0','2E0','2G0']:\n",
        "        training_df = creat_feature(oven=i,days=prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "        testing_df = creat_feature(oven=i,days=prediction_days, new_prediction = lasso_preds )[-prediction_days: - prediction_days+1]\n",
        "        train_df = pd.concat( [train_df, training_df ])\n",
        "        test_df = pd.concat( [test_df, testing_df ])\n",
        "\n",
        "    train_x = train_df.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "    train_y = train_df['anomaly_total_number']\n",
        "\n",
        "    test_1 = test_df[test_df['oven_id']=='1B0']\n",
        "    test_1_x = test_1.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "\n",
        "    imputed_data =  KNNImputer(n_neighbors=3).fit_transform(train_x)\n",
        "    lasso_pred = Lasso().fit(imputed_data, train_y).predict(test_1_x)\n",
        "    print(prediction_days,lasso_pred)\n",
        "    lasso_preds.append(lasso_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRkJ5Hz1z-Jc",
        "outputId": "9231bdbf-13d6-44cb-e38c-406d8dcc845b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56.60776113311742"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(lasso_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbT4Ln1vz-Jd"
      },
      "source": [
        "## 驗證集預測結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY4XHc3Mz-Jd"
      },
      "outputs": [],
      "source": [
        "anormaly_train1 = pd.read_csv('anomaly_train.csv')\n",
        "\n",
        "for i in range(len(anormaly_train1)):\n",
        "    if anormaly_train1['oven_id'][i] == '1.00E+00':\n",
        "        anormaly_train1['oven_id'][i] = '1E0'\n",
        "    elif anormaly_train1['oven_id'][i] == '2.00E+00':\n",
        "        anormaly_train1['oven_id'][i] = '2E0'\n",
        "\n",
        "anormaly_train1['date'] = pd.to_datetime(anormaly_train1['date'],format='%Y-%m-%d')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl0dbkDtz-Jd"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "index = []\n",
        "for i in range(len(anormaly_train1)):\n",
        "    if (anormaly_train1['oven_id'][i][0] == '1') and (anormaly_train1['date'][i]  > datetime.date(2022,8,5)) :\n",
        "            index.append(i)\n",
        "\n",
        "anormaly_train1 = anormaly_train1.drop( index = index ).reset_index().drop(['index'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXPLdeQJz-Jd"
      },
      "outputs": [],
      "source": [
        "# 產線一資料\n",
        "oven,layer,date,anormaly_total_number = [],[],[],[]\n",
        "for d in pd.date_range('2021/12/27','2022/08/05'):\n",
        "  for i in ['1B0','1C0','1D0','1E0','1G0']:\n",
        "    for j in range(1,20):\n",
        "      oven.append(i)\n",
        "      layer.append(j)\n",
        "      date.append(d)\n",
        "      anormaly_total_number.append(0)\n",
        "\n",
        "accumulation = np.zeros(222*5*19)\n",
        "lamp = np.zeros(222*5*19)\n",
        "\n",
        "full_data = {\"oven_id\": oven ,'layer_id':layer,'date':date,\"lamp_id\":lamp,\"anomaly_accumulation_hour\":accumulation,\"anomaly_total_number\":anormaly_total_number }\n",
        "full_data_2 = pd.DataFrame(full_data)\n",
        "\n",
        "all_full_data = pd.concat([full_data_1,full_data_2])\n",
        "\n",
        "#建立2021/12/27-2023/02/06有異常的爐和層的資料\n",
        "# anormaly_train_1 = anormaly_train1[['date','oven_id','layer_id','anomaly_total_number']]\n",
        "\n",
        "#合併2021/12/27-2023/02/06所有爐和所有層的資料\n",
        "df = pd.concat([anormaly_train1,all_full_data])\n",
        "df.drop_duplicates(subset=['date','oven_id','layer_id'], keep='first', inplace=True)\n",
        "df = df.reset_index().drop(['index'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-w5zt_tz-Jd"
      },
      "source": [
        "## 逐步預測法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIjXOVR8z-Jd"
      },
      "outputs": [],
      "source": [
        "def creat_feature(oven,days,new_prediction):\n",
        "    oven_df = df[df['oven_id']== oven ].sort_values(by='date',ascending=True)\n",
        "    oven2_total_anormal = oven_df.groupby(['date'])['anomaly_total_number'].sum()\n",
        "    oven_total_anormal = pd.DataFrame(oven2_total_anormal)\n",
        "\n",
        "    for i in range(27): # 產線一預測後27天，加入後27天的row\n",
        "        oven_total_anormal.loc[222+i] = np.nan\n",
        "\n",
        "    if len(new_prediction) != 0:\n",
        "        for i in range(len(new_prediction)):\n",
        "            oven_total_anormal.loc[222+i] = new_prediction[i]\n",
        "\n",
        "    oven_total_anormal['oven_id'] = oven\n",
        "\n",
        "    # 過去27天的資料\n",
        "    oven_total_anormal['number_sum'] = np.nan\n",
        "    oven_total_anormal['number_max'] = np.nan\n",
        "    oven_total_anormal['number_min'] =  np.nan\n",
        "    oven_total_anormal['number_mode'] = np.nan\n",
        "    oven_total_anormal['days'] = np.nan\n",
        "\n",
        "    # 每個爐的平均損壞數量\n",
        "    oven_total_anormal['oven_encoder'] = oven_total_anormal['anomaly_total_number'].sum() / np.sum(oven_total_anormal['anomaly_total_number'] >0 )\n",
        "\n",
        "    # 個別爐的水冷板溫度、累積時數、Power setup\n",
        "    if oven == '1B0':\n",
        "        oven_total_anormal['cooler_max'] = 30.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[0] ,accumulation_max[0],accumulation_min[0]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[0])\n",
        "\n",
        "    elif oven == '1C0':\n",
        "        oven_total_anormal['cooler_max'] = 30.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[1],accumulation_max[1],accumulation_min[1]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[1])\n",
        "\n",
        "    elif oven == '1D0':\n",
        "        oven_total_anormal['cooler_max'] = 27.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[2],accumulation_max[2],accumulation_min[2]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[2])\n",
        "\n",
        "    elif oven == '1E0':\n",
        "        oven_total_anormal['cooler_max'] = 27\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[3],accumulation_max[3],accumulation_min[3]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[3])\n",
        "\n",
        "    elif oven == '1G0':\n",
        "        oven_total_anormal['cooler_max'] = 30.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[4],accumulation_max[4],accumulation_min[4]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[4])\n",
        "\n",
        "    elif oven == '2B0':\n",
        "        oven_total_anormal['cooler_max'] = 25.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[5] ,accumulation_max[5],accumulation_min[5]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[5])\n",
        "\n",
        "    elif oven == '2C0':\n",
        "        oven_total_anormal['cooler_max'] = 25.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[6],accumulation_max[6],accumulation_min[6]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[6])\n",
        "\n",
        "    elif oven == '2D0':\n",
        "        oven_total_anormal['cooler_max'] = 26\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[7],accumulation_max[7],accumulation_min[7]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[7])\n",
        "\n",
        "    elif oven == '2E0':\n",
        "        oven_total_anormal['cooler_max'] = 25.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[8],accumulation_max[8],accumulation_min[8]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[8])\n",
        "\n",
        "    elif oven == '2G0':\n",
        "        oven_total_anormal['cooler_max'] = 26.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[9],accumulation_max[9],accumulation_min[9]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[9])\n",
        "\n",
        "    # 過去22天的資料\n",
        "    for i in range(days,len(oven_total_anormal)):\n",
        "        oven_total_anormal['number_sum'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_max'][i] = np.max(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_min'][i] = np.min(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        vals,counts = np.unique( oven_total_anormal[i-days:i][ oven_total_anormal['anomaly_total_number'][i-days:i]>0 ]['anomaly_total_number'],return_counts=True)\n",
        "        try:\n",
        "            index = np.argmax(counts)\n",
        "            oven_total_anormal['number_mode'][i] = vals[index]\n",
        "        except: # 找不到眾數\n",
        "            oven_total_anormal['number_mode'][i] = 0\n",
        "        oven_total_anormal['days'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i] >0 )\n",
        "    return oven_total_anormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQI8mYmLz-Je",
        "outputId": "585f8c21-7693-49e4-c46b-ceb9b0fde440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================= oven 1B0 =============================\n",
            "lasso : 50.0\n",
            "============================= oven 1C0 =============================\n",
            "lasso : 45.0\n",
            "============================= oven 1D0 =============================\n",
            "lasso : 43.0\n",
            "============================= oven 1E0 =============================\n",
            "lasso : 41.0\n",
            "============================= oven 1G0 =============================\n",
            "lasso : 4.0\n"
          ]
        }
      ],
      "source": [
        "lasso_predss = []\n",
        "for oven_number in['1B0','1C0','1D0','1E0','1G0']:\n",
        "    print(\"============================= oven \"+oven_number+\" =============================\")\n",
        "    lasso_preds = []\n",
        "    for i in range(27,1,-1):\n",
        "        prediction_days = i\n",
        "\n",
        "        train_df = creat_feature(oven='1B0',days = prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "\n",
        "        if prediction_days == 1 :\n",
        "            test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[248:249]\n",
        "        else:\n",
        "            test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[-prediction_days: - prediction_days+1 ]\n",
        "\n",
        "        for j in ['1C0','1D0','1E0','1G0','2B0','2C0','2D0','2E0','2G0']:\n",
        "            training_df = creat_feature(oven = j ,days=prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "            if prediction_days == 1 :\n",
        "                test_df = creat_feature(oven = j ,days = prediction_days, new_prediction= lasso_preds)[248:249]\n",
        "            else:\n",
        "                testing_df = creat_feature(oven = j ,days=prediction_days, new_prediction = lasso_preds )[-prediction_days: - prediction_days+1]\n",
        "            train_df = pd.concat( [train_df, training_df ])\n",
        "            test_df = pd.concat( [test_df, testing_df ])\n",
        "\n",
        "        train_x = train_df.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "        train_y = train_df['anomaly_total_number']\n",
        "\n",
        "        test_1 = test_df[test_df['oven_id'] == oven_number ]\n",
        "        test_1_x = test_1.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "\n",
        "        imputed_data =  KNNImputer(n_neighbors=3).fit_transform(train_x)\n",
        "        lasso_pred = Lasso().fit(imputed_data, train_y).predict(test_1_x)\n",
        "        lasso_preds.append(lasso_pred)\n",
        "        # print(i)\n",
        "\n",
        "    lasso_preds.append(lasso_preds[-1])\n",
        "    lasso_predss.append(np.round(np.sum(lasso_preds)))\n",
        "    print('lasso :',lasso_predss[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTZb6zMz-Je",
        "outputId": "384ed836-0f69-4a30-9ca1-d7ed5364ec7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================= oven 1B0 =============================\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18816\\416333693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreat_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moven\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_days\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_prediction\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlasso_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m248\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m249\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mtesting_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreat_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moven\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_preds\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprediction_days\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_df\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_df\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18816\\1169143898.py\u001b[0m in \u001b[0;36mcreat_feature\u001b[1;34m(oven, days, new_prediction)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 找不到眾數\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0moven_total_anormal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_mode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0moven_total_anormal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'days'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moven_total_anormal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anomaly_total_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moven_total_anormal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\assd4\\anaconda3\\envs\\tf_2.5_py_3.7\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\assd4\\anaconda3\\envs\\tf_2.5_py_3.7\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                 \u001b[1;31m# to ensure column still in dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m                 \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                 \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                 \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\assd4\\anaconda3\\envs\\tf_2.5_py_3.7\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   3903\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3904\u001b[0m         \u001b[0marraylike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3905\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3907\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\assd4\\anaconda3\\envs\\tf_2.5_py_3.7\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lasso_predss = []\n",
        "for oven_number in['1B0','1C0','1D0','1E0','1G0']:\n",
        "    print(\"============================= oven \"+oven_number+\" =============================\")\n",
        "    lasso_preds = []\n",
        "    for i in range(27,1,-1):\n",
        "        prediction_days = i\n",
        "\n",
        "        train_df = creat_feature(oven='1B0',days = prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "\n",
        "        if prediction_days == 1 :\n",
        "            test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[248:249]\n",
        "        else:\n",
        "            test_df = creat_feature(oven='1B0',days = prediction_days, new_prediction= lasso_preds)[-prediction_days: - prediction_days+1 ]\n",
        "\n",
        "        for j in ['1C0','1D0','1E0','1G0','2B0','2C0','2D0','2E0','2G0']:\n",
        "            training_df = creat_feature(oven = j ,days=prediction_days, new_prediction = lasso_preds )[:-prediction_days]\n",
        "            if prediction_days == 1 :\n",
        "                test_df = creat_feature(oven = j ,days = prediction_days, new_prediction= lasso_preds)[248:249]\n",
        "            else:\n",
        "                testing_df = creat_feature(oven = j ,days=prediction_days, new_prediction = lasso_preds )[-prediction_days: - prediction_days+1]\n",
        "            train_df = pd.concat( [train_df, training_df ])\n",
        "            test_df = pd.concat( [test_df, testing_df ])\n",
        "\n",
        "        train_x = train_df.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "        train_y = train_df['anomaly_total_number']\n",
        "\n",
        "        test_1 = test_df[test_df['oven_id'] == oven_number ]\n",
        "        test_1_x = test_1.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "\n",
        "        imputed_data =  KNNImputer(n_neighbors=3).fit_transform(train_x)\n",
        "        lasso_pred = CatBoostRegressor(silent=True,random_state=42).fit(imputed_data, train_y).predict(test_1_x)\n",
        "        lasso_preds.append(lasso_pred)\n",
        "        # print(i)\n",
        "\n",
        "    lasso_preds.append(lasso_preds[-1])\n",
        "    lasso_predss.append(np.round(np.sum(lasso_preds)))\n",
        "    print('CatBoost :',lasso_predss[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNQCwR2z-Je"
      },
      "source": [
        "## 正常預測法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH8yJmd2z-Je"
      },
      "outputs": [],
      "source": [
        "def creat_feature(oven,days):\n",
        "\n",
        "    oven_df = df[df['oven_id']== oven ].sort_values(by='date',ascending=True)\n",
        "    oven2_total_anormal = oven_df.groupby(['date'])['anomaly_total_number'].sum()\n",
        "    oven_total_anormal = pd.DataFrame(oven2_total_anormal)\n",
        "\n",
        "    for i in range(27): # 產線一預測後27天，加入後27天的row\n",
        "        oven_total_anormal.loc[222+i] = np.nan\n",
        "\n",
        "    oven_total_anormal['oven_id'] = oven\n",
        "\n",
        "    # 過去27天的資料\n",
        "    oven_total_anormal['number_sum'] = np.nan\n",
        "    oven_total_anormal['number_max'] = np.nan\n",
        "    oven_total_anormal['number_min'] =  np.nan\n",
        "    oven_total_anormal['number_mode'] = np.nan\n",
        "    oven_total_anormal['days'] = np.nan\n",
        "\n",
        "    # 每個爐的平均損壞數量\n",
        "    oven_total_anormal['oven_encoder'] = oven_total_anormal['anomaly_total_number'].sum() / np.sum(oven_total_anormal['anomaly_total_number'] >0 )\n",
        "\n",
        "    # 個別爐的水冷板溫度、累積時數、Power setup\n",
        "    if oven == '1B0':\n",
        "        oven_total_anormal['cooler_max'] = 30.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[0] ,accumulation_max[0],accumulation_min[0]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[0])\n",
        "\n",
        "    elif oven == '1C0':\n",
        "        oven_total_anormal['cooler_max'] = 30.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[1],accumulation_max[1],accumulation_min[1]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[1])\n",
        "\n",
        "    elif oven == '1D0':\n",
        "        oven_total_anormal['cooler_max'] = 27.5\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[2],accumulation_max[2],accumulation_min[2]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[2])\n",
        "\n",
        "    elif oven == '1E0':\n",
        "        oven_total_anormal['cooler_max'] = 27\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[3],accumulation_max[3],accumulation_min[3]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[3])\n",
        "\n",
        "    elif oven == '1G0':\n",
        "        oven_total_anormal['cooler_max'] = 30.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[4],accumulation_max[4],accumulation_min[4]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[4])\n",
        "\n",
        "    elif oven == '2B0':\n",
        "        oven_total_anormal['cooler_max'] = 25.9\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[5] ,accumulation_max[5],accumulation_min[5]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[5])\n",
        "\n",
        "    elif oven == '2C0':\n",
        "        oven_total_anormal['cooler_max'] = 25.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[6],accumulation_max[6],accumulation_min[6]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[6])\n",
        "\n",
        "    elif oven == '2D0':\n",
        "        oven_total_anormal['cooler_max'] = 26\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[7],accumulation_max[7],accumulation_min[7]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[7])\n",
        "\n",
        "    elif oven == '2E0':\n",
        "        oven_total_anormal['cooler_max'] = 25.1\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[8],accumulation_max[8],accumulation_min[8]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[8])\n",
        "\n",
        "    elif oven == '2G0':\n",
        "        oven_total_anormal['cooler_max'] = 26.3\n",
        "        oven_total_anormal['avg_accumulation'] ,oven_total_anormal['max_accumulation'] ,oven_total_anormal['min_accumulation'] = accumulation_mean[9],accumulation_max[9],accumulation_min[9]\n",
        "        oven_total_anormal['avg_power_setup'] = power_setup(accumulation_mean[9])\n",
        "\n",
        "    # 過去22天的資料\n",
        "    for i in range(days,len(oven_total_anormal)):\n",
        "        oven_total_anormal['number_sum'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_max'][i] = np.max(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        oven_total_anormal['number_min'][i] = np.min(oven_total_anormal['anomaly_total_number'][i-days:i])\n",
        "        vals,counts = np.unique( oven_total_anormal[i-days:i][ oven_total_anormal['anomaly_total_number'][i-days:i]>0 ]['anomaly_total_number'],return_counts=True)\n",
        "        try:\n",
        "            index = np.argmax(counts)\n",
        "            oven_total_anormal['number_mode'][i] = vals[index]\n",
        "        except: # 找不到眾數\n",
        "            oven_total_anormal['number_mode'][i] = 0\n",
        "        oven_total_anormal['days'][i] = np.sum(oven_total_anormal['anomaly_total_number'][i-days:i] >0 )\n",
        "    return oven_total_anormal\n",
        "\n",
        "def rmse(y,yhat):\n",
        "  return np.sqrt(mean_squared_error(y,yhat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7d03gS6z-Je"
      },
      "outputs": [],
      "source": [
        "prediction_days = 27\n",
        "\n",
        "train_df = creat_feature(oven='1B0',days=prediction_days)[:-prediction_days]\n",
        "test_df = creat_feature(oven='1B0',days=prediction_days)[-prediction_days:]\n",
        "\n",
        "for i in ['1C0','1D0','1E0','1G0','2B0','2C0','2D0','2E0','2G0']:\n",
        "    training_df = creat_feature(oven=i,days=prediction_days)[:-prediction_days]\n",
        "    testing_df = creat_feature(oven=i,days=prediction_days)[-prediction_days:]\n",
        "    train_df = pd.concat( [train_df, training_df ])\n",
        "    test_df = pd.concat( [test_df, testing_df ])\n",
        "\n",
        "train_x = train_df.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "train_y = train_df['anomaly_total_number']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MCPtrWjz-Jf",
        "outputId": "7f7e614d-fbc7-4539-8e7c-a3ce8655d5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================= Test prediction on oven 1B0 =============================\n",
            "lasso : 32.0 | ElasticNet : 31.0 | LGBM : 60.0 | XGB : 46.0 | Catboost :  57.0\n",
            "============================= Test prediction on oven 1C0 =============================\n",
            "lasso : 30.0 | ElasticNet : 29.0 | LGBM : 16.0 | XGB : 53.0 | Catboost :  73.0\n",
            "============================= Test prediction on oven 1D0 =============================\n",
            "lasso : 31.0 | ElasticNet : 31.0 | LGBM : 68.0 | XGB : 55.0 | Catboost :  49.0\n",
            "============================= Test prediction on oven 1E0 =============================\n",
            "lasso : 30.0 | ElasticNet : 30.0 | LGBM : 93.0 | XGB : 47.0 | Catboost :  113.0\n",
            "============================= Test prediction on oven 1G0 =============================\n",
            "lasso : 3.0 | ElasticNet : 2.0 | LGBM : 1.0 | XGB : 1.0 | Catboost :  1.0\n"
          ]
        }
      ],
      "source": [
        "lasso_preds,en_preds,lgb_preds,xgb_preds,cat_preds,actual = [],[],[],[],[],[]\n",
        "lgb_params = {'n_estimators': 900, 'learning_rate': 0.08108549380709631, 'reg_lambda': 7.400420560246068, 'subsample': 0.6262267316079506, 'min_child_samples': 7, 'max_depth': 9}\n",
        "xgb_params = {'n_estimators': 1300, 'learning_rate': 0.024658403720628174, 'booster': 'gbtree', 'lambda': 8.65039444200474, 'alpha': 7.841025757534408, 'subsample': 0.9651727299534355, 'colsample_bytree': 0.8353388492801248, 'max_depth': 8, 'min_child_weight': 3, 'eta': 0.8339832871331261, 'gamma': 0.6596571553899819, 'grow_policy': 'lossguide'}\n",
        "cat_params = {'iterations': 600, 'learning_rate': 0.08077046387065928, 'depth': 7, 'l2_leaf_reg': 9.566779128474014, 'bagging_temperature': 3.857521071572685, 'random_strength': 4.330651960392663, 'border_count': 47}\n",
        "\n",
        "for i in ['1B0','1C0','1D0','1E0','1G0']:\n",
        "# for i in ['2B0','2C0','2D0','2E0','2G0']:\n",
        "    print(\"============================= Test prediction on oven \"+i+\" =============================\")\n",
        "    test_1 = test_df[test_df['oven_id']==i]\n",
        "    test_1_x = test_1.drop(['anomaly_total_number','oven_id'],axis=1)\n",
        "\n",
        "    # 执行KNN插补\n",
        "    imputed_data =  KNNImputer(n_neighbors=3).fit_transform(train_x)\n",
        "    # imputed_data = train_x.fillna(0)\n",
        "\n",
        "    lasso_pred = Lasso().fit(imputed_data, train_y).predict(test_1_x)\n",
        "    en_pred = ElasticNet().fit(imputed_data, train_y).predict(test_1_x)\n",
        "    xgb_pred = XGBRegressor(random_state= 42,**xgb_params).fit(train_x, train_y).predict(test_1_x)\n",
        "    lgb_pred = LGBMRegressor(random_state= 42,**lgb_params).fit(train_x, train_y).predict(test_1_x)\n",
        "    cat_pred = CatBoostRegressor(random_state= 42,silent=True).fit(train_x, train_y).predict(test_1_x)\n",
        "\n",
        "    lasso_preds.append(np.round(np.sum(lasso_pred)))\n",
        "    en_preds.append(np.round(np.sum(en_pred)))\n",
        "    lgb_preds.append(np.round(np.sum(lgb_pred)))\n",
        "    xgb_preds.append(np.round(np.sum(xgb_pred)))\n",
        "    cat_preds.append(np.round(np.sum(cat_pred)))\n",
        "    print('lasso :',lasso_preds[-1],'| ElasticNet :', en_preds[-1],'| LGBM :',lgb_preds[-1],'| XGB :',xgb_preds[-1],'| Catboost : ',cat_preds[-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}